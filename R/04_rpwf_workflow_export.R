# rpwf_workflow_set() ----------------------------------------------------------
#' Customized Version of `{workflowsets}`
#'
#' Wrapper around [tidyr::crossing()] that creates all combinations of recipes
#' and models.
#'
#' @param preprocs list or vector of [recipes::recipe()].
#' @param models list or vector of model spec. Generated by adding
#' [set_py_engine()] to a model, e.g. [parsnip::boost_tree()] and
#' [parsnip::set_engine()].
#' @param costs list or vector of sklearn cost optimization metrics such as
#' "neg_log_loss" and "roc_auc".
#'
#' @return tibble that contains a combination of list of recipes, models,
#' and costs.
#' @export
#' @examples
#' d <- rpwf_sim_()$train
#' m1 <- parsnip::boost_tree() |>
#'   parsnip::set_engine("xgboost") |>
#'   parsnip::set_mode("classification") |>
#'   set_py_engine(py_module = "xgboost", py_base_learner = "XGBClassifier")
#' r1 <- d |>
#'   recipes::recipe(target ~ .) |>
#'   recipes::step_dummy(.data$X3, one_hot = TRUE) |>
#'   # "pd.index" is the special column that used for indexing in pandas
#'   recipes::update_role(.data$id, new_role = "pd.index")
#' wf <- rpwf_workflow_set(list(r1), list(m1), "neg_log_loss")
#' wf
rpwf_workflow_set <- function(preprocs, models, costs) {
  stopifnot(is.vector(preprocs) & is.vector(models) & is.vector(costs))
  list_class_fns <- function(list) {
    c <- unique(sapply(list, class))
    return(c)
  }

  stopifnot("preproc accept list of recipes" = "recipe" == list_class_fns(preprocs))
  stopifnot("models accept list of models" = "model_spec" %in% list_class_fns(models) &
    !"recipe" %in% list_class_fns(models))
  stopifnot("costs accept list of characters" = "character" %in% list_class_fns(costs))

  df <- tidyr::crossing(
    preprocs = unique(preprocs), models = unique(models), costs = unique(costs)
  )

  df$costs <- as.character(costs) # results is a list, this unlist that
  class(df) <- append(class(df), "rpwf_workflow_set")
  return(df)
}

# rpwf_tag_recipe() ----------------------------------------------------------
#' Add a Tag to a Recipe
#'
#' Complicated workflow sets can become difficult to track. Add a tag to keep
#' track of unique recipes.
#'
#' @param obj An [recipes::recipe()] object.
#' @param tag Short description of recipe.
#'
#' @return A tagged [recipes::recipe()] object. Accessible with `obj$recipe_tag`.
#' @export
#'
#' @examples
#' r <- recipes::recipe(~., data = mtcars)
#' r <- rpwf_tag_recipe(r, "test recipe")
#' r$recipe_tag
rpwf_tag_recipe <- function(obj, tag) {
  obj$recipe_tag <- tag
  return(obj)
}

#' Wrapper to Generate the Object to be Exported to the Database
#'
#' @param wflow_obj object created by the [rpwf_workflow_set()] function.
#' @inheritParams rpwf_write_grid
#' @inheritParams rpwf_grid_gen_
#' @inheritParams rpwf_add_random_state_
#'
#' @return tibble with the columns necessary for exporting to db.
#' @export
#' @examples
#' # Create the database
#' temp_dir <- withr::local_tempdir()
#' db_con <- rpwf_connect_db("db.SQLite", temp_dir)
#'
#' # Create a `workflow_set`
#' d <- rpwf_sim_()$train
#' m1 <- parsnip::boost_tree() |>
#'   parsnip::set_engine("xgboost") |>
#'   parsnip::set_mode("classification") |>
#'   set_py_engine(py_module = "xgboost", py_base_learner = "XGBClassifier")
#' r1 <- d |>
#'   recipes::recipe(target ~ .) |>
#'   recipes::step_dummy(.data$X3, one_hot = TRUE) |>
#'   # "pd.index" is the special column that used for indexing in pandas
#'   recipes::update_role(.data$id, new_role = "pd.index")
#' wf <- rpwf_workflow_set(list(r1), list(m1), "neg_log_loss")
#'
#' to_export <- wf |>
#'   rpwf_augment(db_con, dials::grid_latin_hypercube, size = 10)
#' list.files(paste0(temp_dir, "/rpwfDb"), recursive = TRUE) # Files are created
rpwf_augment <- function(wflow_obj, db_con, .grid_fun = NULL,
                         ..., range = c(1L, 5000L), seed = 1234L) {
  py_module <- py_base_learner <- engine <- rename_fns <- model_mode <- NULL
  set.seed(seed)
  wflow_obj |>
    rpwf_add_model_param_(db_con$con) |>
    rpwf_add_desc_() |>
    rpwf_add_py_model_(db_con$con) |>
    rpwf_add_random_state_(range, seed) |>
    rpwf_add_grid_(.grid_fun, seed, ...) |>
    rpwf_Rgrid_R6_(db_con) |>
    rpwf_TrainDf_R6_(db_con) |>
    dplyr::select(-c(py_module, py_base_learner, engine, rename_fns, model_mode))
}

# rpwf_augment.default <- function(obj) {
#   return(obj)
# }
#
# rpwf_augment.rpwf_workflow_set <- function() {
#
# }

# rpwf_write_<obj>() ----------------------------------------------------------
#' Write the Hyper Param Grid Parquet File
#'
#' @param obj obj generated by [rpwf_augment()].
#'
#' @details
#' For each grid, initialize a new [RGrid], call `self$export()`, then return
#' the object. This make sure the same object called twice will just fetch
#' the result from the previous call. Hence, can't be run in parallel.
#'
#' At this point, we made sure that 1) the db is updated, 2) file is exported,
#' 3) file exists. Use the hashes for getting the grid id.
#'
#' @return Parquet files.
#' @export
rpwf_write_grid <- function(obj) {
  stopifnot("Run rpwf_augment() first!" = "Rgrid" %in% names(obj))
  for (g in obj$Rgrid) {
    g$export()$set_attrs() # Export and update information in the db
  }
}

#' Write the Train/Test Data
#'
#' @param obj obj generated by [rpwf_augment()].
#' @param seed random seed. To control for recipes such as down sampling.
#'
#' @details
#' For each recipe, initialize a new [TrainDf], call `self$export()`, then return
#' the object. This make sure the same object called twice will just fetch the
#' result from the previous call.
#'
#' @return Parquet files.
#' @export
rpwf_write_df <- function(obj, seed = 1234) {
  stopifnot("Run rpwf_augment() first!" = "TrainDf" %in% names(obj))
  for (r in obj$TrainDf) {
    set.seed(seed)
    r$export()$set_attrs()
  }
}

#' Generate the Export to DB functions
#'
#' @param required_col String of required columns.
#'
#' @return a function that add the required columns to the database.
#' @noRd
rpwf_export_fns_ <- function(required_cols) {
  fns <- function(obj, db_con) {
    rpwf <- rpwf_parquet_id_(obj = obj, db_con = db_con)

    # These columns must be present
    required <- force(required_cols)

    # Query the wflow that's already in the database
    db_wflow_hash <- rpwf_wflow_hash_(
      dplyr::select(
        DBI::dbGetQuery(db_con$con, glue::glue("SELECT * FROM wflow_tbl;")),
        dplyr::all_of(required)
      )
    )

    # Generate hash of current wflows
    to_export_hash <- rpwf_wflow_hash_(dplyr::select(rpwf, dplyr::all_of(required)))
    matched_wflow <- to_export_hash %in% db_wflow_hash

    if (any(matched_wflow)) {
      message("the following workflows are already in the database\n")
      print(rpwf[matched_wflow, which(names(rpwf) %in% required)])
    }
    # Only add the workflow that's not in the database
    to_export <- as.data.frame(rpwf[!matched_wflow, which(names(rpwf) %in% required)])

    if (nrow(to_export) == 0) {
      message("All workflows found in db, exiting...")
      return(0)
    } else {
      message("Exporting workflows to db...")
      DBI::dbAppendTable(db_con$con, name = "wflow_tbl", value = to_export)
    }
  }
  return(fns)
}

#' Export the [rpwf_augment()] Object into the Database
#'
#' @inheritParams rpwf_Rgrid_R6_
#'
#' @return number of rows exported.
#' @export
#' @examples
#' # Create the database
#' temp_dir <- withr::local_tempdir()
#' db_con <- rpwf_connect_db("db.SQLite", temp_dir)
#'
#' # Create a `workflow_set`
#' d <- mtcars
#' d$target <- stats::rbinom(nrow(d), 1, 0.5)
#' m1 <- parsnip::boost_tree() |>
#'   parsnip::set_engine("xgboost") |>
#'   parsnip::set_mode("classification") |>
#'   set_py_engine("xgboost", "XGBClassifier", "my_xgboost_model")
#' r1 <- d |>
#'   recipes::recipe(target ~ .)
#' wf <- rpwf_workflow_set(list(r1), list(m1), "neg_log_loss")
#'
#' to_export <- wf |>
#'   rpwf_augment(db_con, dials::grid_latin_hypercube, size = 10)
#' rpwf_write_grid(to_export, db_con)
#' rpwf_write_df(to_export, db_con)
#'
#' # Before exporting
#' DBI::dbGetQuery(db_con$con, "SELECT * FROM wflow_tbl;")
#' # After exporting
#' rpwf_export_wfs(to_export, db_con)
#' DBI::dbGetQuery(db_con$con, "SELECT * FROM wflow_tbl;")
rpwf_export_wfs <- rpwf_export_fns_(
  c(
    "df_id",
    "grid_id",
    "model_tag",
    "recipe_tag",
    "costs",
    "model_type_id",
    "random_state",
    "py_base_learner_args"
  )
)
