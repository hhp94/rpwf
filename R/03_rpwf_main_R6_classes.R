# BaseEx -----------------------------------------------------------------------
#' @title Internal R6 Object Only for Setting up Inheritance
#'
#' @description
#' A R6 object that provides a common set of methods to 1) store the metadata of
#' data in the db, and 2) export parquet files for python to import. Not
#' meant to be called manually.
#' @keywords internal
BaseEx <- R6::R6Class(
  "BaseEx",
  public = list(
    #' @field hash (`character()`)\cr
    #' hash of the object by [rlang::hash()].
    hash = NULL,
    #' @field pin_name (`character()`)\cr
    #' pin_name of the file in the project folder.
    pin_name = NULL,
    #' @field df (`data.frame()`)\cr
    #' the df for the hyper param grid or the transformed df.
    df = NULL,
    #' @field con (`DBI::dbConnect()`)\cr
    #' a [DBI::dbConnect()] object, generated by [rpwf_connect_db()].
    con = NULL,
    #' @field export_query (`glue::glue_sql()`)\cr
    #' SQL query to upload metadata of the data into the db.
    export_query = NULL,
    #' @field queried_pin_name (`glue::glue_sql()`)\cr
    #' Queried pin_name of the object.
    queried_pin_name = NULL,
    #' @field board (`character()`)\cr
    #' a `{pins}` board object.
    board = NULL,
    #' @field dbname name of the database.
    dbname = NULL,
    #' @field seed random seed.
    seed = NULL,

    #' @description
    #' This class is the parent of RGrid and TrainDf R6 object, not meant to be
    #' called.
    #' @param db_con (`DbCon`)\cr
    #' a `DbCon` object, generated by [rpwf_connect_db()].
    initialize = function(db_con) {
      stopifnot("input should be a R6 DbCon() object" = R6::is.R6(db_con))
      self$seed <- NULL
      self$pin_name <- NULL
      self$df <- NULL
      self$con <- db_con$con
      self$dbname <- db_con$dbname
      self$hash <- NULL
      self$export_query <- NULL
      self$queried_pin_name <- NULL
      self$board <- db_con$board
    },

    #' @description
    #' Run the query that check if the object exists in the db by checking the
    #' hash of the object in the db. Either find one unique row or no row.
    #' @param query (`glue::glue_sql()`)\cr
    #' SQL query for either the hyper parameter grid or the transformed df.
    exec_query = function(query) {
      DBI::dbGetQuery(self$con, query, list(self$hash))
    },

    #' @description
    #' Pass the hash of the object to this function to set the hash attribute.
    #' @param val (`any`)\cr
    #' New hash, either an integer or string.
    set_hash = function(val) {
      self$hash <- as.character(val)
    },

    #' @description
    #' Change the pin_name where the object is stored. Is NA only when no grid is
    #' provided. Have to provide a train data.
    #' @param val (`character()`)\cr
    #' Path to store the object on disk.
    set_pin_name = function(val) {
      self$pin_name <- val
    },

    #' @description
    #' Store the results of the query from the db in a data.frame. Query have to
    #' return a df (so [nrow()] works) with 0 <= `nrow()` < 2.
    #' @param val (`data.frame()`)\cr
    #' New data frame generated by `self$exec_query`.
    find_pin_name_in_db = function(val) {
      stopifnot(is.data.frame(val) & nrow(val) < 2 & nrow(val) >= 0)
      self$queried_pin_name <- val
    },

    #' @description
    #' Change the SQL query to export metadata to database.
    #' @param val (`glue::glue_sql()`)\cr
    #' New SQL query to export metadata.
    set_export_query = function(val) {
      self$export_query <- val
    },

    #' @description
    #' If the hash of the new object is not found in the database, then new
    #' data is prepared. If the data is found in the metadata but not in the
    #' indicated pin_name then new data is also prepared. Otherwise, `self$df` is
    #' NULL and will be skipped by the `BaseEx::self$export_parquet()` method.
    #' @param val (`data.frame()`)\cr
    #' Either a [recipes::juice()] object or a data.frame of the hyper param grid.
    set_df = function(val) {
      stopifnot("Wrap object around rlang::expr" = rlang::is_expression(val))
      # find_pin_name_in_db() must be run first
      if (nrow(self$queried_pin_name) == 0L) {
        # If query yields 0 rows, then create df
        # message(glue::glue("Preparing new {type}..."))
        self$df <- eval(val)
        # Query can return NA pin_name for the NA grid
      } else if (!is.na(self$queried_pin_name$pin_name) &
        !pins::pin_exists(self$board, self$queried_pin_name$pin_name)) {
        # If parquet file not found but is in found in database
        # message(glue::glue("Metadata found, but new {type} is needed..."))
        self$df <- eval(val)
      } # Otherwise no transformation needed, leave `self$df` as NULL
      # else {
      #   # message(glue::glue("{type} parquet found in {self$db_folder}"))
      # }
    },

    #' @description
    #' If the db query found no existing metadata, then an export pin_name is made.
    #' If the metadata is found but the associated data is not found, then an
    #' export pin_name is also made. Else get the pin_name from the metadata in the db.
    #' @param new_pin_name (`character()`)\cr
    #' Path to the object.
    #' @param new_export_query (`glue::glue_sql()`)\cr
    #' SQL query to export the obj metadata to the db.
    export_prep = function(new_pin_name, new_export_query) {
      # If the query generate no entry, then make a pin_name
      if (nrow(self$queried_pin_name) == 0L) {
        self$set_pin_name(new_pin_name)
        self$set_export_query(new_export_query)
      } else {
        # Else get the pin_name from the query results and assign to `self$pin_name`
        self$set_pin_name(self$queried_pin_name$pin_name)
        self$set_export_query(NULL)
      }
    },

    #' @description
    #' If the `self$export_query` is generated because metadata is not found in
    #' the database, then export the metadata to the db using this query.
    #' Otherwise return NULL.
    export_db = function() {
      if (!is.null(self$export_query)) {
        # message("Exporting to db")
        DBI::dbExecute(self$con, self$export_query) # if an export query is created
        self$set_export_query(NULL) # then run the query and reset to NULL
      }
      invisible(self)
    },

    #' @description
    #' If the file specified by `self$pin_name` is not found, then export the file
    #' as a parquet file to the location specified in the metadata.
    export_parquet = function() {
      if (is.na(self$pin_name)) {
        message("No grid generated\n")
      } else if (!pins::pin_exists(self$board, self$pin_name)) {
        # message("Writing parquet file\n")
        pins::pin_write(self$board, x = self$df, name = self$pin_name, type = "arrow")
      } else {
        # message("Parquet file found\n")
      }
      invisible(self)
    },

    #' @description
    #' Wrapper around exporting information to the db and writing the parquet
    #' file.
    export = function() {
      self$export_db()$export_parquet()
      invisible(self)
    }
  )
)


# TrainDf ----------------------------------------------------------------------
#' @title Internal R6 Object that Process the Data Transformation
#'
#' @description
#' A R6 object that manage the export of metadata and parquet file of the
#' transformed data defined by the recipe for data transformation. Accept a
#' special role `"pd.index"` from the [recipes::update_role()] as an index for
#' a pandas DataFrame. If no outcome is provided, then the `data.frame` is
#' considered a "test" `data.frame.`
#'
#' @details
#' This object works by:
#' + inherits from the [BaseEx] class.
#' + accept a recipe and generate a prepped object with [recipes::prep()].
#' + use the prepped object to get the name of the pd.index, target, and
#' predictors.
#' + calculate the hash of the prepped recipe (not the data frame) and check
#' the hash of the prepped recipe in the database.
#' + if the hash is found in the database:
#'   + assign the pin_name associated with the hash of the data.frame to `self$pin_name`.
#'   + check if the file exists with the `self$pin_name`.
#'   + if not exists, transform the prepped object with [recipes::juice()] and
#'    assign to `self$df`.
#'   + if the file exists, then assign `NULL` to `self$df` attribute to stop
#'   `self$export_parquet()` from executing.
#' + if the hash is not found in the database:
#'   + transform the prepped object with [recipes::juice()] and assign to
#'   `self$df`.
#'   + generate a new pin_name to write the transformed data.
#'   + generate a SQL query to update the database with the new hash and new pin_name
#' + update the database with the generated SQL query with `self$export_db()`
#' + write the parquet with `self$export_parquet()`
#' @keywords internal
TrainDf <- R6::R6Class(
  "TrainDf",
  inherit = BaseEx,
  public = list(
    #' @field prepped (`recipes::prep()`)\cr
    #' holds the prepped object.
    prepped = NULL,
    #' @field term_info (`tibble::tibble()`)\cr
    #' the `self$prepped` object has the attribute `term_info` that has
    #' information of transformed variable before actually transforming the data.
    term_info = NULL,
    #' @field idx_col (`character()`)\cr
    #' Having a pre-defined index in R makes working with `pandas.DataFrame` less
    #' error prone. Defined by the provided recipe.
    idx_col = NULL,
    #' @field target (`character()`)\cr
    #' Name of the target variable. If missing, then a message is returned to say
    #' that a test df is assumed to be generated. Defined by the provided recipe.
    target = NULL,
    #' @field predictors (`character()`)\cr
    #' List of names of the predictors. Stored as JSON string to be parsed in
    #' python into a python list.
    predictors = NULL,
    # Holds the recipe to transform the data.

    #' @description
    #' Create a new instance of the TrainDf class. Accept a
    #' special role `"pd.index"` from the [recipes::update_role()] as an index for
    #' a pandas DataFrame. If no outcome is provided, then the `data.frame` is
    #' considered a "test" `data.frame`. See `?rprw::BaseEx` for
    #' details about the attributes and methods.
    #' @param recipe (`recipes::recipe()`)\cr
    #' provided recipe that defines how the data is transformed.
    #' @param db_con (`DbCon`)\cr
    #' a `DbCon` object, generated by [rpwf_connect_db()].
    #' @param seed (`numeric()`)\cr
    #' Random seed to control recipe at the prep level
    initialize = function(recipe, db_con, seed = sample(1:1e5, size = 1)) {
      stopifnot("a recipe object required" = "recipe" %in% class(recipe))
      stopifnot("seed should be an integer" = (length(seed) == 1))
      super$initialize(db_con) # Init from the super class
      self$seed <- seed
      set.seed(self$seed)
      # Recipe tag shouldn't be added to the prepped object for hashing.
      self$prepped <- recipes::prep(recipe) # Init the prepped object
      self$term_info <- self$prepped$term_info # post-transform train metadata
      self$set_hash(rlang::hash(self$prepped)) # Set the hash of the prepped obj
      self$set_idx_col() # set index column for pandas
      self$set_target_col() # set target column for pandas
      self$set_predictors() # get the predictors
      # self$set_attrs() # Doesn't cost much because only prep is ran.
    },

    #' @description
    #' Refresh the attributes using the current hash. Needed to be run because
    #' it updates the attributes with information from the Db
    set_attrs = function() {
      # use the hash of the prepped to find the pin_name
      self$find_pin_name_in_db(self$exec_query(
        glue::glue_sql("SELECT df_pin_name AS pin_name FROM df_tbl WHERE df_hash = ?",
          .con = self$con
        )
      ))
      self$set_df(rlang::expr(recipes::juice(self$prepped)))
      self$export_prep(
        new_pin_name = glue::glue("df.{self$hash}.parquet"),
        new_export_query = glue::glue_sql(
          "INSERT INTO df_tbl (idx_col, target, predictors, df_pin_name, df_hash)
            VALUES ({vals*})",
          vals = c(
            self$idx_col, self$target, self$predictors, self$pin_name, self$hash
          ), .con = self$con
        )
      ) # Get the pin_name for parquet file
      invisible(self)
    },

    #' @description
    #' Set the index column as defined by the recipe.
    set_idx_col = function() {
      idx <- which(self$term_info$role == "pd.index") # which var is "index"
      if (length(idx) == 1) {
        self$idx_col <- self$term_info[idx, "variable", drop = TRUE]
        message(glue::glue("Adding {self$idx_col} as pandas idx"))
      } else {
        message("No pandas idx added. Use update_roles() with 'pd.index' for one")
        self$idx_col <- NA
      }
      invisible(self)
    },

    #' @description
    #' Set the target column as defined by the recipe. Assume to be test data
    #' if the target is not found.
    set_target_col = function() {
      targ <- which(self$term_info$role == "outcome") # which var is "outcome"
      if (length(targ) == 1L) {
        self$target <- self$term_info[targ, "variable", drop = TRUE]
      } else {
        message("No outcome added. Update recipe, or assuming this is test data")
        self$target <- NA
      }
      invisible(self)
    },

    #' @description
    #' Store the list of predictors defined by the recipe as a json string
    #' to be parsed in python.
    set_predictors = function() {
      pred <- which(self$term_info$role == "predictor") # which are predictors
      stopifnot("Must have more than 0 predictors" = length(pred) > 0)
      self$predictors <- as.character(
        jsonlite::toJSON(self$term_info[pred, "variable", drop = TRUE])
      )
    }
  )
)

# RGrid ------------------------------------------------------------------------
#' @title Internal R6 object that process the hyper param grid generated in R
#'
#' @description
#' A R6 object that manage the export of metadata and parquet file of the
#' hyper param grid generated in R
#'
#' @details
#' This object works by:
#' + inherits from the [BaseEx] class.
#' + accept a hyper param grid generated with [rpwf_grid_gen_].
#' + calculate the hash of the grid and check the hash is in the database.
#' + if the hash is found in the database:
#'   + assign the pin_name associated with the hash of the grid to `self$pin_name`.
#'   + check if the grid exists with `self$pin_name`.
#'   + if not exists, assign the grid to `self$df`.
#'   + if the file exists, then assign `NULL` to the `self$df` attribute to stop
#'   `self$export_parquet()` from executing.
#' + if the hash is not found in the database:
#'   + assign the grid to `self$df`.
#'   + generate a new pin_name to write the grid.
#'   + generate a SQL query to update the database with the new hash and new pin_name
#' + update the database with the generated SQL query with `self$export_db()`
#' + write the parquet with `self$export_parquet()`
#' @keywords internal
RGrid <- R6::R6Class(
  "RGrid",
  inherit = BaseEx,
  public = list(
    #' @field grid_obj (`character()`)\cr
    #' [rpwf_grid_gen_()] performs necessary clean ups before the grid can
    #' be used in python
    grid_obj = NULL,
    #' @description
    #' Create a new instance of the RGrid class. These are grids made by
    #' functions such as `dials::grid_latin_hypercube` and `dials::grid_regular`.
    #' See [BaseEx] for details of the attributes.
    #' @param grid_obj (`rpwf::rpwf_grid_gen_()`)\cr
    #' [rpwf_grid_gen_()] performs necessary clean ups before the grid can
    #' be used in python.
    #' @param db_con (`DbCon`)\cr
    #' a `DbCon` object, generated by [rpwf_connect_db()].
    initialize = function(grid_obj, db_con) {
      super$initialize(db_con) # Init from the super class
      self$grid_obj <- grid_obj
      self$set_hash(rlang::hash(grid_obj)) # hash the grid
      # self$set_attrs()
    },

    #' @description
    #' Refresh the attributes using the current hash. Needed to be run because
    #' it updates the attributes with information from the Db
    set_attrs = function() {
      # use the hash of the prepped to find the pin_name
      self$find_pin_name_in_db(self$exec_query(
        glue::glue_sql( # hash is passed into ?
          "SELECT grid_pin_name AS pin_name FROM r_grid_tbl WHERE grid_hash = ?",
          .con = self$con
        )
      ))
      self$set_df(rlang::expr(self$grid_obj))
      self$export_prep(
        new_pin_name = glue::glue("grid.{self$hash}.parquet"),
        new_export_query = glue::glue_sql(
          "INSERT INTO r_grid_tbl (grid_pin_name, grid_hash) VALUES ({vals*})",
          vals = c(self$pin_name, self$hash),
          .con = self$con
        ) # Get the pin_name for parquet file
      )
      invisible(self)
    }
  )
)

# Functions related to hyper param grids ---------------------------------------

#' Create a Tune Grid Specific to the Provided Model Spec
#'
#' The hyper parameter grid can either be provided with this function or all at
#' once later on with [rpwf_augment()]
#'
#' @inheritParams set_py_engine
#' @param .model_grid_fun a `dials::grid_<functions>`, e.g., `grid_random()`,
#' `grid_latin_hypercube()`.
#' @param .model_update_params update {dials} functions such as [dials::penalty()]
#' and [dials::cost()] with a named list. See examples.
#' @param ... arguments to pass to `.model_grid_fun`.
#'
#' @return Add the `{dials}` function and associated arguments to the model spec
#' @export
#'
#' @examples
#' m <- parsnip::boost_tree() |>
#'   parsnip::set_engine("xgboost") |>
#'   parsnip::set_mode("classification") |>
#'   set_r_grid(dials::grid_random, list(trees = dials::trees(range = c(2, 3))), size = 5)
#' m$.model_grid_fun
#' m$.model_grid_fun_args
set_r_grid <- function(obj, .model_grid_fun, .model_update_params = NULL, ...) {
  stopifnot(".model_grid_fun needs to be function" = is.function(.model_grid_fun))
  obj$.model_grid_fun <- .model_grid_fun
  obj$.model_update_params <- .model_update_params
  obj$.model_grid_fun_args <- rlang::exprs(...)
  return(obj)
}
